{
  "10": {
    "inputs": {
      "switch_1": "On",
      "controlnet_1": "mistoLine_rank256.safetensors",
      "controlnet_strength_1": 1.34,
      "start_percent_1": 0,
      "end_percent_1": 1,
      "switch_2": "On",
      "controlnet_2": "sai_xl_depth_256lora.safetensors",
      "controlnet_strength_2": 0.9,
      "start_percent_2": 0,
      "end_percent_2": 1,
      "switch_3": "Off",
      "controlnet_3": "control_v11p_sd15_seg_fp16.safetensors",
      "controlnet_strength_3": 1,
      "start_percent_3": 0,
      "end_percent_3": 1,
      "image_1": ["28", 0],
      "image_2": ["59", 0]
    },
    "class_type": "CR Multi-ControlNet Stack",
    "_meta": {
      "title": "🕹️ CR Multi-ControlNet Stack"
    }
  },
  "11": {
    "inputs": {
      "images": ["28", 0]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "12": {
    "inputs": {
      "model_name": "4x-UltraSharp.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "14": {
    "inputs": {
      "image": "lukesf_visitors_at_travel_and_tourism_booth_on_exhibition_--sty_924acc9e-d22d-4142-92c0-a13b154151f7.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Upload Your picture"
    }
  },
  "15": {
    "inputs": {
      "images": ["59", 0]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "16": {
    "inputs": {
      "ckpt_name": "airtistRealisticXL_v50Lightning.safetensors",
      "vae_name": "Baked VAE",
      "clip_skip": -1,
      "lora_name": "None",
      "lora_model_strength": 1,
      "lora_clip_strength": 1,
      "positive": ["22", 0],
      "negative": ["21", 0],
      "token_normalization": "none",
      "weight_interpretation": "comfy",
      "empty_latent_width": ["30", 2],
      "empty_latent_height": ["29", 2],
      "batch_size": 1,
      "cnet_stack": ["10", 0]
    },
    "class_type": "Efficient Loader",
    "_meta": {
      "title": "Efficient Loader"
    }
  },
  "18": {
    "inputs": {
      "image": "kingsmendigitalexperience_httpss.mj.runEUIBRI8kjmQ_make_it_sm_7ad776c8-dad9-4bf1-90e0-a3f251837ef2_2.png",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Reference Style"
    }
  },
  "19": {
    "inputs": {
      "Input": 2,
      "model1": ["16", 0],
      "model2": ["37", 0]
    },
    "class_type": "CR Model Input Switch",
    "_meta": {
      "title": "style influence on/off"
    }
  },
  "20": {
    "inputs": {
      "max_width": 768,
      "max_height": 768,
      "min_width": 0,
      "min_height": 0,
      "crop_if_required": "no",
      "images": ["14", 0]
    },
    "class_type": "ConstrainImage|pysssss",
    "_meta": {
      "title": "Constrain Image 🐍"
    }
  },
  "21": {
    "inputs": {
      "prompt": "words, texts,low quality, bad quality, worse quality, people, embedding:quality\\EasyNegativeV2, embedding:quality\\FastNegativeV2, embedding:quality\\bad-picture-chill-75v, "
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "Negative Prompt"
    }
  },
  "22": {
    "inputs": {
      "prompt": "a exhibition space"
    },
    "class_type": "CR Prompt Text",
    "_meta": {
      "title": "Positive Prompt"
    }
  },
  "24": {
    "inputs": {
      "seed": 379856091774493
    },
    "class_type": "Seed",
    "_meta": {
      "title": "Seed"
    }
  },
  "25": {
    "inputs": {
      "upscale_model": ["12", 0],
      "image": ["40", 5]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "28": {
    "inputs": {
      "coarse": "disable",
      "resolution": 1024,
      "image": ["14", 0]
    },
    "class_type": "LineArtPreprocessor",
    "_meta": {
      "title": "Realistic Lineart"
    }
  },
  "29": {
    "inputs": {
      "number_type": "integer",
      "number": 1080
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Constant Number"
    }
  },
  "30": {
    "inputs": {
      "number_type": "integer",
      "number": 1920
    },
    "class_type": "Constant Number",
    "_meta": {
      "title": "Constant Number"
    }
  },
  "34": {
    "inputs": {
      "samples1": ["16", 3],
      "samples2": ["35", 0]
    },
    "class_type": "LatentAdd",
    "_meta": {
      "title": "LatentAdd"
    }
  },
  "35": {
    "inputs": {
      "pixels": ["14", 0],
      "vae": ["16", 4]
    },
    "class_type": "VAEEncode",
    "_meta": {
      "title": "VAE Encode"
    }
  },
  "36": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": ["16", 0]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter Unified Loader"
    }
  },
  "37": {
    "inputs": {
      "weight": 1.75,
      "weight_type": "style transfer precise",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": ["36", 0],
      "ipadapter": ["36", 1],
      "image": ["18", 0]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  },
  "38": {
    "inputs": {
      "batch_size": 1,
      "latent": ["35", 0]
    },
    "class_type": "CR Latent Batch Size",
    "_meta": {
      "title": "⚙️ CR Latent Batch Size"
    }
  },
  "39": {
    "inputs": {
      "scale": 0.5,
      "blur_sigma": 2.8000000000000003,
      "model": ["19", 0]
    },
    "class_type": "SelfAttentionGuidance",
    "_meta": {
      "title": "Self-Attention Guidance"
    }
  },
  "40": {
    "inputs": {
      "seed": ["24", 3],
      "steps": 4,
      "cfg": 1.4000000000000001,
      "sampler_name": "dpmpp_2m_sde_gpu",
      "scheduler": "simple",
      "denoise": 0.9400000000000001,
      "preview_method": "none",
      "vae_decode": "true",
      "model": ["52", 0],
      "positive": ["16", 1],
      "negative": ["16", 2],
      "latent_image": ["38", 0],
      "optional_vae": ["16", 4]
    },
    "class_type": "KSampler (Efficient)",
    "_meta": {
      "title": "KSampler (Efficient)"
    }
  },
  "52": {
    "inputs": {
      "Input": 1,
      "model1": ["19", 0],
      "model2": ["39", 0]
    },
    "class_type": "CR Model Input Switch",
    "_meta": {
      "title": "self attention guidance on/off"
    }
  },
  "59": {
    "inputs": {
      "a": 6.28,
      "bg_threshold": 0.1,
      "resolution": 512,
      "image": ["20", 0]
    },
    "class_type": "MiDaS-DepthMapPreprocessor",
    "_meta": {
      "title": "MiDaS Depth Map"
    }
  },
  "61": {
    "inputs": {
      "filename_prefix": "",
      "folder": "",
      "overwrite_warning": false,
      "include_metadata": true,
      "extension": "png",
      "quality": 95,
      "images": ["25", 0]
    },
    "class_type": "> Save Image",
    "_meta": {
      "title": "😼> Save Image"
    }
  }
}
